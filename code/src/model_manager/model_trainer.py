import pandas as pd
import numpy as np
import joblib
import json
from pathlib import Path
from typing import Dict, List, Any, Tuple
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
import warnings

warnings.filterwarnings('ignore')


class ModelTrainer:
    """Ù…Ø¯ÛŒØ± Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ - Ø¹Ù…ÙˆÙ…ÛŒ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…Ø¬Ø¯Ø¯"""

    def __init__(self, config):
        self.config = config
        self.models = {}
        self.preprocessors = {}
        self.training_reports = {}

    def create_preprocessor(self, strategy_name: str) -> Pipeline:
        """Ø§ÛŒØ¬Ø§Ø¯ Ù¾Ø§ÛŒÙ¾Ù„Ø§ÛŒÙ† Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø®Ø§Øµ"""
        preprocessor = Pipeline([
            ('scaler', StandardScaler())
        ])
        return preprocessor

    def train_base_models(self, X_train: pd.DataFrame, y_train: pd.Series,
                          strategy_name: str) -> Dict[str, Any]:
        """Ø¢Ù…ÙˆØ²Ø´ ØªÙ…Ø§Ù… Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ"""
        print(f"ðŸŽ¯ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ: {strategy_name}")

        # Ø§ÛŒØ¬Ø§Ø¯ preprocessor
        preprocessor = self.create_preprocessor(strategy_name)

        # Ø¢Ù…ÙˆØ²Ø´ preprocessor
        X_processed = preprocessor.fit_transform(X_train)
        self.preprocessors[strategy_name] = preprocessor

        trained_models = {}
        training_results = {}

        for model_name, model_config in self.config.BASE_MODELS.items():
            print(f"   ðŸ”§ Ø¢Ù…ÙˆØ²Ø´ {model_name}...")

            try:
                # Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¯Ù„
                model_class = globals()[model_config['class']]
                model = model_class(**model_config['params'])

                # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
                model.fit(X_processed, y_train)

                # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„
                trained_models[model_name] = model
                training_results[model_name] = {
                    'status': 'success',
                    'training_samples': len(X_train),
                    'feature_count': X_processed.shape[1]
                }

                print(f"   âœ… {model_name} Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯")

            except Exception as e:
                training_results[model_name] = {
                    'status': 'failed',
                    'error': str(e)
                }
                print(f"   âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù…ÙˆØ²Ø´ {model_name}: {e}")

        self.models[strategy_name] = trained_models
        self.training_reports[strategy_name] = training_results

        return trained_models

    def hyperparameter_tuning(self, X_train: pd.DataFrame, y_train: pd.Series,
                              strategy_name: str, model_names: List[str] = None) -> Dict[str, Any]:
        """ØªÙ†Ø¸ÛŒÙ… Ù‡Ø§ÛŒÙ¾Ø±Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ - Ø§ØµÙ„Ø§Ø­ Ù†Ù‡Ø§ÛŒÛŒ"""
        if model_names is None:
            model_names = ['svm', 'random_forest']

        print(f"âš™ï¸  ØªÙ†Ø¸ÛŒÙ… Ù‡Ø§ÛŒÙ¾Ø±Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ: {strategy_name}")

        tuned_models = {}
        tuning_results = {}

        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² preprocessor Ø¢Ù…ÙˆØ²Ø´ Ø¯ÛŒØ¯Ù‡
        preprocessor = self.preprocessors.get(strategy_name)
        if preprocessor is None:
            print(f"   âš ï¸  Preprocessor Ø¨Ø±Ø§ÛŒ {strategy_name} ÛŒØ§ÙØª Ù†Ø´Ø¯ - Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯ÛŒØ¯")
            preprocessor = self.create_preprocessor(strategy_name)
            X_processed = preprocessor.fit_transform(X_train)
            self.preprocessors[strategy_name] = preprocessor
        else:
            X_processed = preprocessor.transform(X_train)

        # ðŸ”§ Ø§ØµÙ„Ø§Ø­: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² RandomState Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡â€ŒØ¨Ø±Ø¯Ø§Ø±ÛŒ
        if len(X_processed) > 5000:
            print(f"   ðŸ“‰ Ú©Ø§Ù‡Ø´ Ø­Ø¬Ù… Ø¯Ø§Ø¯Ù‡ Ø§Ø² {len(X_processed)} Ø¨Ù‡ 5000 Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø±Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ…â€ŒÙ‡Ø§ÛŒÙ¾Ø±Ù¾Ø§Ø±Ø§Ù…ØªØ±")

            # ðŸ”¥ Ø§ØµÙ„Ø§Ø­ Ø®Ø·Ø§: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² RandomState Ø¨Ù‡ Ø¬Ø§ÛŒ random_state
            rng = np.random.RandomState(self.config.RANDOM_STATE)
            indices = rng.choice(len(X_processed), size=5000, replace=False)

            X_sampled = X_processed[indices]
            y_sampled = y_train.iloc[indices]
        else:
            X_sampled = X_processed
            y_sampled = y_train

        print(f"   âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø´Ø¯Ù‡: X={X_sampled.shape}, y={len(y_sampled)}")

        for model_name in model_names:
            if model_name not in self.config.HYPERPARAM_GRIDS:
                print(f"   âš ï¸  Ù‡Ø§ÛŒÙ¾Ø±Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ {model_name} ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡")
                continue

            print(f"   ðŸ” ØªÙ†Ø¸ÛŒÙ… {model_name}...")

            try:
                # Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡
                model_config = self.config.BASE_MODELS[model_name]
                model_class = globals()[model_config['class']]
                base_model = model_class(**model_config['params'])

                # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù‡Ø§ÛŒÙ¾Ø±Ù¾Ø§Ø±Ø§Ù…ØªØ±
                param_grid = self.config.HYPERPARAM_GRIDS[model_name]

                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² RandomizedSearchCV
                search = RandomizedSearchCV(
                    base_model, param_grid,
                    n_iter=10,
                    cv=3,
                    scoring='f1_macro',
                    n_jobs=self.config.N_JOBS,
                    random_state=self.config.RANDOM_STATE,
                    verbose=1
                )

                # Ø§Ø¬Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø´Ø¯Ù‡
                print(f"   â³ Ø´Ø±ÙˆØ¹ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù‡Ø§ÛŒÙ¾Ø±Ù¾Ø§Ø±Ø§Ù…ØªØ± Ø¨Ø±Ø§ÛŒ {model_name}...")
                search.fit(X_sampled, y_sampled)

                # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ù†Ù‡Ø§ÛŒÛŒ Ø±ÙˆÛŒ ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ø¨Ù‡ØªØ±ÛŒÙ† Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§
                print(f"   ðŸŽ¯ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ù†Ù‡Ø§ÛŒÛŒ {model_name} Ø±ÙˆÛŒ ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...")
                best_model = model_class(**search.best_params_)
                best_model.fit(X_processed, y_train)

                # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ ØªÙ†Ø¸ÛŒÙ…â€ŒØ´Ø¯Ù‡
                tuned_models[model_name] = best_model
                tuning_results[model_name] = {
                    'best_params': search.best_params_,
                    'best_score': search.best_score_,
                    'training_samples': len(X_processed),
                    'status': 'success'
                }

                print(f"   âœ… {model_name} ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯ (best score: {search.best_score_:.3f})")

            except Exception as e:
                tuning_results[model_name] = {
                    'status': 'failed',
                    'error': str(e)
                }
                print(f"   âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙ†Ø¸ÛŒÙ… {model_name}: {e}")

        return tuned_models, tuning_results


    def _simplify_cv_results(self, cv_results: Dict[str, Any]) -> Dict[str, Any]:
        """Ø³Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†ØªØ§ÛŒØ¬ CV Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ"""
        simplified = {}
        for key, values in cv_results.items():
            if key.startswith('param_') or key in ['mean_test_score', 'std_test_score', 'rank_test_score']:
                # ÙÙ‚Ø· Û±Û° Ù†ØªÛŒØ¬Ù‡ Ø¨Ø±ØªØ± Ø±Ø§ Ù†Ú¯Ù‡ Ø¯Ø§Ø±
                if len(values) > 10:
                    simplified[key] = values[:10].tolist() if hasattr(values, 'tolist') else values[:10]
                else:
                    simplified[key] = values.tolist() if hasattr(values, 'tolist') else values
        return simplified

    def save_models(self, base_models: Dict[str, Dict[str, Any]],
                    tuned_models: Dict[str, Any], strategy_name: str):
        """Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªÙ…Ø§Ù… Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ùˆ preprocessorÙ‡Ø§"""

        # Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§
        base_path = Path(self.config.MODEL_SAVE_PATHS['base_models']) / strategy_name
        tuned_path = Path(self.config.MODEL_SAVE_PATHS['tuned_models'])
        preprocessor_path = Path(self.config.MODEL_SAVE_PATHS['preprocessors'])

        base_path.mkdir(parents=True, exist_ok=True)
        tuned_path.mkdir(parents=True, exist_ok=True)
        preprocessor_path.mkdir(parents=True, exist_ok=True)

        # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡
        for model_name, model in base_models.get(strategy_name, {}).items():
            model_path = base_path / f"{model_name}.pkl"
            joblib.dump(model, model_path)
            print(f"   ðŸ’¾ Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡ {model_name} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")

        # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ…â€ŒØ´Ø¯Ù‡
        for model_name, model in tuned_models.items():
            model_path = tuned_path / f"{model_name}_{strategy_name}_tuned.pkl"
            joblib.dump(model, model_path)
            print(f"   ðŸ’¾ Ù…Ø¯Ù„ ØªÙ†Ø¸ÛŒÙ…â€ŒØ´Ø¯Ù‡ {model_name} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")

        # Ø°Ø®ÛŒØ±Ù‡ preprocessor
        preprocessor = self.preprocessors.get(strategy_name)
        if preprocessor:
            preprocessor_path_file = preprocessor_path / f"{strategy_name}_preprocessor.pkl"
            joblib.dump(preprocessor, preprocessor_path_file)
            print(f"   ðŸ’¾ Preprocessor {strategy_name} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
        else:
            print(f"   âš ï¸  Preprocessor Ø¨Ø±Ø§ÛŒ {strategy_name} ÛŒØ§ÙØª Ù†Ø´Ø¯")

        print(f"ðŸ’¾ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ {strategy_name} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯")

    def get_training_summary(self) -> Dict[str, Any]:
        """Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬ Ø¢Ù…ÙˆØ²Ø´"""
        summary = {
            'total_strategies': len(self.models),
            'strategies_trained': list(self.models.keys()),
            'models_per_strategy': {},
            'preprocessors_trained': list(self.preprocessors.keys())
        }

        for strategy, models in self.models.items():
            summary['models_per_strategy'][strategy] = {
                'total_models': len(models),
                'successful_models': sum(1 for m in models.values() if m is not None),
                'model_names': list(models.keys())
            }

        return summary