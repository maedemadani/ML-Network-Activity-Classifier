
import pandas as pd
import numpy as np
import json
from pathlib import Path
import sys
import os
from sklearn.model_selection import train_test_split
from typing import Dict, Any

current_dir = os.path.dirname(__file__)
balance_manager_path = os.path.join(current_dir, 'balance_manager')
if balance_manager_path not in sys.path:
    sys.path.insert(0, balance_manager_path)

try:
    from balancing.imbalance_analyzer import ImbalanceAnalyzer
    from balancing.sampling_strategies import AdaptiveSamplingStrategies
    from balancing.data_validator import DataValidator
    from balancing.balance_reporter import BalanceReporter
    from config.balancing_config import BalanceConfig

    print("âœ… ØªÙ…Ø§Ù… Ù…Ø§Ú˜ÙˆÙ„â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª import Ø´Ø¯Ù†Ø¯")
except ImportError as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± import: {e}")
    sys.exit(1)


class DataBalancer:
    """Ù…Ø¯ÛŒØ± Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§"""

    def __init__(self, config=None):
        self.config = config or BalanceConfig()
        self.analyzer = ImbalanceAnalyzer(self.config)
        self.sampler = AdaptiveSamplingStrategies(self.config)
        self.validator = DataValidator(self.config)
        self.reporter = BalanceReporter(self.config)

        self.results = {}
        self.reports = {}

    def run_balancing_pipeline(self, input_file: str, output_dir: str = None) -> Dict[str, Any]:
        """Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„ Ù¾Ø§ÛŒÙ¾Ù„Ø§ÛŒÙ† Ù…Ø¯ÛŒØ±ÛŒØª Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„"""
        print("=" * 60)
        print("ÙØ§Ø² Û³: Ù…Ø¯ÛŒØ±ÛŒØª Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§")
        print("=" * 60)

        # Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡ Ø®Ø±ÙˆØ¬ÛŒ
        if output_dir is None:
            output_dir = Path(__file__).parent.parent / "data" / "balancedData"
        else:
            output_dir = Path(output_dir)

        output_dir.mkdir(parents=True, exist_ok=True)

        try:
            # Û±. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
            print("ğŸ“¥ Ù…Ø±Ø­Ù„Ù‡ Û±: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù†Ø¯Ø³ÛŒâ€ŒØ´Ø¯Ù‡...")
            df = pd.read_csv(input_file)
            print(f"   âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯: {df.shape}")

            # Û². ØªØ´Ø®ÛŒØµ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø³ØªÙˆÙ† Ù‡Ø¯Ù
            print("\nğŸ¯ Ù…Ø±Ø­Ù„Ù‡ Û²: Ù…Ø¯ÛŒØ±ÛŒØª Ø³ØªÙˆÙ† Ù‡Ø¯Ù Ùˆ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ø¯Ø±...")
            target_column = self.analyzer.detect_target_column(df)
            print(f"   âœ… Ø³ØªÙˆÙ† Ù‡Ø¯Ù Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯: {target_column}")

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ X Ùˆ y
            X = df.drop(columns=[target_column])
            y = df[target_column]

            # Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ø¯Ø±
            y_processed = self.analyzer.handle_rare_classes(y)

            # Û³. ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ Train/Test
            print("\nâœ‚ï¸  Ù…Ø±Ø­Ù„Ù‡ Û³: ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ Train/Test...")
            X_train, X_test, y_train, y_test = train_test_split(
                X, y_processed,
                test_size=self.config.TEST_SIZE,
                stratify=y_processed,
                random_state=self.config.RANDOM_STATE
            )

            print(f"   âœ… Train set: {X_train.shape}, Test set: {X_test.shape}")

            # Û´. ØªØ­Ù„ÛŒÙ„ Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„
            print("\nğŸ“Š Ù…Ø±Ø­Ù„Ù‡ Û´: ØªØ­Ù„ÛŒÙ„ Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„...")
            analysis_report = self.analyzer.analyze_class_distribution(y_train)
            self.reports['analysis'] = analysis_report

            print(f"   âœ… Ù†Ø³Ø¨Øª Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„: {analysis_report['imbalance_metrics']['imbalance_ratio']:.1f}")
            print(f"   ğŸ”§ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§: {len(analysis_report['recommendations'])} Ù…ÙˆØ±Ø¯")

            # Ûµ. Ø§ÛŒØ¬Ø§Ø¯ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡â€ŒØ¨Ø±Ø¯Ø§Ø±ÛŒ
            print("\nğŸ”§ Ù…Ø±Ø­Ù„Ù‡ Ûµ: Ø§ÛŒØ¬Ø§Ø¯ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡â€ŒØ¨Ø±Ø¯Ø§Ø±ÛŒ...")
            balanced_data = self.sampler.apply_sampling(X_train, y_train)
            sampling_report = self.sampler.get_sampling_report()
            self.reports['sampling'] = sampling_report

            print(f"   âœ… Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù‡: {list(balanced_data.keys())}")

            # Û¶. Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ
            print("\nğŸ” Ù…Ø±Ø­Ù„Ù‡ Û¶: Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ØªØ¹Ø§Ø¯Ù„...")
            original_data = {'X': X_train, 'y': y_train}
            validation_report = self.validator.validate_balanced_data(original_data, balanced_data)
            self.reports['validation'] = validation_report

            # Û·. Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†ØªØ§ÛŒØ¬
            print("\nğŸ’¾ Ù…Ø±Ø­Ù„Ù‡ Û·: Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†ØªØ§ÛŒØ¬...")
            self._save_balanced_datasets(balanced_data, X_test, y_test, output_dir)

            # Û¸. ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´
            print("\nğŸ“ˆ Ù…Ø±Ø­Ù„Ù‡ Û¸: ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§...")
            final_report = self.reporter.generate_comprehensive_report(
                analysis_report, sampling_report, validation_report, output_dir
            )

            # Û¹. Ù…ØµÙˆØ±Ø³Ø§Ø²ÛŒ
            print("\nğŸ¨ Ù…Ø±Ø­Ù„Ù‡ Û¹: Ø§ÛŒØ¬Ø§Ø¯ Ù…ØµÙˆØ±Ø³Ø§Ø²ÛŒâ€ŒÙ‡Ø§...")
            self.analyzer.create_visualizations(
                y_train,
                {k: v['y'] for k, v in balanced_data.items() if k != 'original'},
                output_dir / "balance_visualizations.png"
            )

            print(f"\nğŸ‰ ÙØ§Ø² Û³ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª completed Ø´Ø¯!")
            print(f"ğŸ“ Ù†ØªØ§ÛŒØ¬ Ø¯Ø±: {output_dir}")

            return {
                'balanced_data': balanced_data,
                'test_data': {'X': X_test, 'y': y_test},
                'reports': self.reports,
                'output_dir': output_dir
            }

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ ÙØ§Ø² Û³: {e}")
            import traceback
            traceback.print_exc()
            return {}

    def _save_balanced_datasets(self, balanced_data: Dict[str, Any],
                                X_test: pd.DataFrame, y_test: pd.Series,
                                output_dir: Path):
        """Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªÙ…Ø§Ù… Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡"""

        # Ø°Ø®ÛŒØ±Ù‡ ØªØ³Øª set
        test_dir = output_dir / "test"
        test_dir.mkdir(exist_ok=True)

        X_test.to_csv(test_dir / "X_test.csv", index=False)
        y_test.to_csv(test_dir / "y_test.csv", index=False)

        # Ø°Ø®ÛŒØ±Ù‡ Ù‡Ø± Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ
        for strategy_name, data_dict in balanced_data.items():
            strategy_dir = output_dir / strategy_name
            strategy_dir.mkdir(exist_ok=True)

            X_data = data_dict['X']
            y_data = data_dict['y']

            X_data.to_csv(strategy_dir / "X_train.csv", index=False)
            y_data.to_csv(strategy_dir / "y_train.csv", index=False)

            print(f"   ğŸ’¾ {strategy_name}: {X_data.shape}")

        print(f"   âœ… ØªÙ…Ø§Ù… Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯")


def main(input_file=None, output_dir=None):
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø§Ø¬Ø±Ø§ÛŒ ÙØ§Ø² Û³"""
    if input_file is None:
        input_file = "../data/engineered_dataset.csv"

    print("=" * 60)
    print("ÙØ§Ø² Û³: Ù…Ø¯ÛŒØ±ÛŒØª Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ - Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø³ØªÙ‚Ù„")
    print("=" * 60)

    try:
        # Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¯ÛŒØ± ØªØ¹Ø§Ø¯Ù„
        balance_manager = DataBalancer()

        # Ø§Ø¬Ø±Ø§ÛŒ Ù¾Ø§ÛŒÙ¾Ù„Ø§ÛŒÙ†
        results = balance_manager.run_balancing_pipeline(input_file, output_dir)

        if results:
            print(f"\nğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬:")
            print(f"   â€¢ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù‡: {list(results['balanced_data'].keys())}")
            print(f"   â€¢ Ø§Ø¨Ø¹Ø§Ø¯ ØªØ³Øª set: {results['test_data']['X'].shape}")
            print(f"   â€¢ Ù¾ÙˆØ´Ù‡ Ø®Ø±ÙˆØ¬ÛŒ: {results['output_dir']}")

            return results
        else:
            print("âŒ ÙØ§Ø² Û³ Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯")
            return None

    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ ÙØ§Ø² Û³: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='ÙØ§Ø² Û³: Ù…Ø¯ÛŒØ±ÛŒØª Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§')
    parser.add_argument('--input', type=str, help='ÙØ§ÛŒÙ„ ÙˆØ±ÙˆØ¯ÛŒ', default='../data/engineeredData/engineered_dataset.csv')
    parser.add_argument('--output', type=str, help='Ù¾ÙˆØ´Ù‡ Ø®Ø±ÙˆØ¬ÛŒ', default=None)

    args = parser.parse_args()

    main(input_file=args.input, output_dir=args.output)