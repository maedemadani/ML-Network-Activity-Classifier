```python

```

# ğŸ”¬ Ù†ÙˆØªâ€ŒØ¨ÙˆÚ© ØªØ­Ù„ÛŒÙ„ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ÙØ¹Ø§Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø´Ø¨Ú©Ù‡

**Ù†ÙˆØ¹:** Ù†ÙˆØªâ€ŒØ¨ÙˆÚ© ØªÙˆØ³Ø¹Ù‡â€ŒØ§ÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ÛŒ
**Ù‡Ø¯Ù:** Ù…Ø³ØªÙ†Ø¯Ø³Ø§Ø²ÛŒ ÙØ±Ø¢ÛŒÙ†Ø¯ ØªÙˆØ³Ø¹Ù‡ØŒ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÛŒØ§Ù†ÛŒ Ùˆ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒâ€ŒÙ‡Ø§ÛŒ ÙÙ†ÛŒ
**Ù…Ø®Ø§Ø·Ø¨:** ØªÛŒÙ… ØªÙˆØ³Ø¹Ù‡ Ùˆ ØªØ­Ù„ÛŒÙ„â€ŒÚ¯Ø±Ø§Ù† ÙÙ†ÛŒ
**ØªØ§Ø±ÛŒØ®:** 27/07/1404


## ğŸ“‹ ÙÙ‡Ø±Ø³Øª Ù…Ø­ØªÙˆØ§

Û±. [Ù…Ø¹Ø±ÙÛŒ Ù¾Ø±ÙˆÚ˜Ù‡ Ùˆ Ø§Ù‡Ø¯Ø§Ù](#Û±)
Û². [Ø§Ú©ØªØ´Ø§Ù Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ Ø§ÙˆÙ„ÛŒÙ‡](#Û²)
Û³. [Ù…Ù‡Ù†Ø¯Ø³ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ - ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ](#Û³)
Û´. [Ù…Ø¯ÛŒØ±ÛŒØª Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„ - Ø¢Ø²Ù…Ø§ÛŒØ´ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§](#Û´)
Ûµ. [Ù…Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ - Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§](#Ûµ)
Û¶. [Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ Trade-off](#Û¶)
Û·. [Ù†ØªØ§ÛŒØ¬ Ùˆ Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ÛŒ Ú©Ø³Ø¨â€ŒØ´Ø¯Ù‡](#Û·)



<a id='Û±'></a>
## Û±. ğŸ¯ Ù…Ø¹Ø±ÙÛŒ Ù¾Ø±ÙˆÚ˜Ù‡ Ùˆ Ø§Ù‡Ø¯Ø§Ù


### Ø§Ù‡Ø¯Ø§Ù Ø§ØµÙ„ÛŒ:
- ØªÙˆØ³Ø¹Ù‡ Ù…Ø¯Ù„ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ ÙØ¹Ø§Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø´Ø¨Ú©Ù‡
- ØªÙ…Ø±Ú©Ø² Ø¨Ø± Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ (deny/drop)
- Ù…Ø¯ÛŒØ±ÛŒØª Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„ Ø´Ø¯ÛŒØ¯ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
- Ø§ÛŒØ¬Ø§Ø¯ Ù¾Ø§ÛŒÙ¾Ù„Ø§ÛŒÙ† Ú©Ø§Ù…Ù„ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø³ØªÙ‚Ø±Ø§Ø±


### Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡:


Ø¯Ø§Ø¯Ù‡ Ø®Ø§Ù… â†’ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ â†’ Ù…Ù‡Ù†Ø¯Ø³ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒ â†’ Ù…Ø¯ÛŒØ±ÛŒØª ØªØ¹Ø§Ø¯Ù„ â†’ Ù…Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ â†’ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ



```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
import joblib
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…Ø§ÛŒØ´
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")
pd.set_option('display.max_columns', 50)
pd.set_option('display.width', 1000)

print("âœ… Ù…Ø­ÛŒØ· ØªÙˆØ³Ø¹Ù‡ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯")
```

    âœ… Ù…Ø­ÛŒØ· ØªÙˆØ³Ø¹Ù‡ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯


<a id='Û²'></a>
## Û². ğŸ” Ø§Ú©ØªØ´Ø§Ù Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ Ø§ÙˆÙ„ÛŒÙ‡



```python
data_path = "../../data/network_logs.csv"
df_raw = pd.read_csv(data_path)

print("ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù…:")
print(f"â€¢ Ø§Ø¨Ø¹Ø§Ø¯ Ø¯Ø§Ø¯Ù‡: {df_raw.shape}")
print(f"â€¢ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§: {list(df_raw.columns)}")

```

    ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù…:
    â€¢ Ø§Ø¨Ø¹Ø§Ø¯ Ø¯Ø§Ø¯Ù‡: (65532, 12)
    â€¢ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§: ['Source Port', 'Destination Port', 'NAT Source Port', 'NAT Destination Port', 'Action', 'Bytes', 'Bytes Sent', 'Bytes Received', 'Packets', 'Elapsed Time (sec)', 'pkts_sent', 'pkts_received']



```python
class_dist = df_raw['Action'].value_counts()
class_dist_pct = df_raw['Action'].value_counts(normalize=True) * 100

print("ğŸ“ˆ ØªÙˆØ²ÛŒØ¹ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ù‡Ø¯Ù:")
for action, (count, pct) in enumerate(zip(class_dist, class_dist_pct)):
    print(f"  {action}: {count:,} Ù†Ù…ÙˆÙ†Ù‡ ({pct:.2f}%)")

```

    ğŸ“ˆ ØªÙˆØ²ÛŒØ¹ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ù‡Ø¯Ù:
      0: 37,640 Ù†Ù…ÙˆÙ†Ù‡ (57.44%)
      1: 14,987 Ù†Ù…ÙˆÙ†Ù‡ (22.87%)
      2: 12,851 Ù†Ù…ÙˆÙ†Ù‡ (19.61%)
      3: 54 Ù†Ù…ÙˆÙ†Ù‡ (0.08%)



```python
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

# Ù†Ù…ÙˆØ¯Ø§Ø± Ù…ÛŒÙ„Ù‡â€ŒØ§ÛŒ
colors = ['#2ecc71', '#e74c3c', '#f39c12', '#3498db']
bars = ax1.bar(class_dist.index, class_dist.values, color=colors)
ax1.set_title('ØªÙˆØ²ÛŒØ¹ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ù‡Ø¯Ù - ØªØ¹Ø¯Ø§Ø¯', fontweight='bold')
ax1.set_xlabel('Ú©Ù„Ø§Ø³')
ax1.set_ylabel('ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡')
for bar, count in zip(bars, class_dist.values):
    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 100,
             f'{count:,}', ha='center', va='bottom')

# Ù†Ù…ÙˆØ¯Ø§Ø± Ø¯Ø§ÛŒØ±Ù‡â€ŒØ§ÛŒ
ax2.pie(class_dist.values, labels=class_dist.index, autopct='%1.1f%%',
        colors=colors, startangle=90)
ax2.set_title('ØªÙˆØ²ÛŒØ¹ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ù‡Ø¯Ù - Ø¯Ø±ØµØ¯', fontweight='bold')

plt.tight_layout()
plt.show()
```


    
![png](../Analysis_Reports/analysis_report_files/../Analysis_Reports/analysis_report_11_0.png)
    


### ğŸ” Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡:
- **Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„ Ø´Ø¯ÛŒØ¯**: Ú©Ù„Ø§Ø³ `allow` Ø¨Ø§ Û¶Ûµ.Û´Û¹Ùª Ø§Ú©Ø«Ø±ÛŒØª Ø¯Ø§Ø±Ø¯
- **Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ Ù†Ø§Ø¯Ø±**: `deny` (Û±Û´.Û°Û·Ùª) Ùˆ `drop` (Û²Û°.Û³ÛµÙª)
- **Ú©Ù„Ø§Ø³ Ø¨Ø³ÛŒØ§Ø± Ù†Ø§Ø¯Ø±**: `reset-both` ØªÙ†Ù‡Ø§ Û°.Û°Û¹Ùª


<a id='Û³'></a>
## Û³. âš™ï¸ Ù…Ù‡Ù†Ø¯Ø³ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ - ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ



```python
engineered_path = "../../data/engineeredData/engineered_dataset.csv"
df_engineered = pd.read_csv(engineered_path)

# ØªØ­Ù„ÛŒÙ„ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
original_features = set(df_raw.columns)
engineered_features = set(df_engineered.columns)
new_features = engineered_features - original_features

print("ğŸ¯ ØªØ­Ù„ÛŒÙ„ Ù…Ù‡Ù†Ø¯Ø³ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§:")
print(f"â€¢ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡: {len(original_features)}")
print(f"â€¢ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ: {len(engineered_features)}")
print(f"â€¢ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯: {len(new_features)}")

```

    ğŸ¯ ØªØ­Ù„ÛŒÙ„ Ù…Ù‡Ù†Ø¯Ø³ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§:
    â€¢ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡: 12
    â€¢ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ: 48
    â€¢ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯: 36



```python
feature_categories = {
    'Ù¾ÙˆØ±ØªÛŒ': [f for f in new_features if 'port' in f.lower()],
    'ØªØ±Ø§ÙÛŒÚ©ÛŒ': [f for f in new_features if any(x in f.lower() for x in ['byte', 'packet', 'ratio'])],
    'Ø²Ù…Ø§Ù†ÛŒ': [f for f in new_features if any(x in f.lower() for x in ['time', 'second', 'duration'])],
    'ØªØ¹Ø§Ù…Ù„ÛŒ': [f for f in new_features if any(x in f.lower() for x in ['flow', 'interaction', 'balance'])],
    'ØªØ¨Ø¯ÛŒÙ„â€ŒØ´Ø¯Ù‡': [f for f in new_features if 'log1p' in f.lower()],
    'Ø³Ø§ÛŒØ±': [f for f in new_features if not any(keyword in f.lower() for keyword in
                                              ['port', 'byte', 'time', 'flow', 'log1p'])]
}

print("ğŸ“Š Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯:")
for category, features in feature_categories.items():
    if features:
        print(f"  â€¢ {category}: {len(features)} ÙˆÛŒÚ˜Ú¯ÛŒ")
        for feature in features[:3]:  # Ù†Ù…Ø§ÛŒØ´ Û³ ÙˆÛŒÚ˜Ú¯ÛŒ Ø§ÙˆÙ„
            print(f"    - {feature}")

```

    ğŸ“Š Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯:
      â€¢ Ù¾ÙˆØ±ØªÛŒ: 15 ÙˆÛŒÚ˜Ú¯ÛŒ
        - Source Port_category_registered
        - Destination Port_is_http
        - log1p_NAT Destination Port
      â€¢ ØªØ±Ø§ÙÛŒÚ©ÛŒ: 15 ÙˆÛŒÚ˜Ú¯ÛŒ
        - log1p_Bytes
        - log1p_packets_per_second
        - log1p_avg_packet_size
      â€¢ Ø²Ù…Ø§Ù†ÛŒ: 7 ÙˆÛŒÚ˜Ú¯ÛŒ
        - log1p_packets_per_second
        - bytes_per_second
        - duration_category_long
      â€¢ ØªØ¹Ø§Ù…Ù„ÛŒ: 1 ÙˆÛŒÚ˜Ú¯ÛŒ
        - is_small_flow
      â€¢ ØªØ¨Ø¯ÛŒÙ„â€ŒØ´Ø¯Ù‡: 10 ÙˆÛŒÚ˜Ú¯ÛŒ
        - log1p_NAT Destination Port
        - log1p_Bytes
        - log1p_packets_per_second
      â€¢ Ø³Ø§ÛŒØ±: 9 ÙˆÛŒÚ˜Ú¯ÛŒ
        - is_short_session
        - duration_category_long
        - packets_per_second



```python
numeric_features = df_engineered.select_dtypes(include=[np.number]).columns.tolist()
if 'Action' in numeric_features:
    numeric_features.remove('Action')

# Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§ Ù‡Ø¯Ù (Ø§Ú¯Ø± Ù‡Ø¯Ù Ø¹Ø¯Ø¯ÛŒ Ø¨Ø§Ø´Ø¯)
if 'Action' in df_engineered.columns and df_engineered['Action'].dtype in [np.int64, np.float64]:
    correlations = df_engineered[numeric_features].corrwith(df_engineered['Action']).abs().sort_values(ascending=False)

    print("ğŸ”— Û±Û° ÙˆÛŒÚ˜Ú¯ÛŒ Ø¨Ø§ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§ Ù‡Ø¯Ù:")
    for i, (feature, corr) in enumerate(correlations.head(10).items()):
        print(f"  {i+1}. {feature}: {corr:.3f}")

```

    ğŸ”— Û±Û° ÙˆÛŒÚ˜Ú¯ÛŒ Ø¨Ø§ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§ Ù‡Ø¯Ù:
      1. NAT Source Port_is_well_known: 0.976
      2. NAT Source Port_category_well_known: 0.976
      3. has_nat: 0.976
      4. dst_port_nat_match: 0.976
      5. is_short_session: 0.974
      6. duration_category_short: 0.974
      7. log1p_packets_per_second: 0.971
      8. log1p_bytes_per_second: 0.970
      9. log1p_NAT Destination Port: 0.952
      10. pkts_sent_ratio: 0.929


### ğŸ’¡ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ Ø¯Ø± Ù…Ù‡Ù†Ø¯Ø³ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒ:
Û±. **ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾ÙˆØ±ØªÛŒ**: Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù¾ÙˆØ±Øªâ€ŒÙ‡Ø§ Ø¨Ù‡ Well-Known, Registered, Ephemeral
Û². **Ù†Ø³Ø¨Øªâ€ŒÙ‡Ø§ÛŒ ØªØ±Ø§ÙÛŒÚ©ÛŒ**: Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø³Ø¨Øª Ø§Ø±Ø³Ø§Ù„/Ø¯Ø±ÛŒØ§ÙØª Ø¨Ø±Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ØºÛŒØ±Ø¹Ø§Ø¯ÛŒ
Û³. **ØªØ¨Ø¯ÛŒÙ„ Ù„Ú¯Ø§Ø±ÛŒØªÙ…ÛŒ**: Ú©Ø§Ù‡Ø´ skewness Ø¯Ø± ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§ ØªÙˆØ²ÛŒØ¹ Ù†Ø§Ù…ØªÙ‚Ø§Ø±Ù†
Û´. **Ù¾Ø±Ú†Ù…â€ŒÙ‡Ø§ÛŒ NAT**: Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ØªØ±Ø§ÙÛŒÚ©â€ŒÙ‡Ø§ÛŒ ØªØ­Øª ØªØ£Ø«ÛŒØ± Network Address Translation


<a id='Û´'></a>
## Û´. âš–ï¸ Ù…Ø¯ÛŒØ±ÛŒØª Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„ - Ø¢Ø²Ù…Ø§ÛŒØ´ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§



```python
# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†ØªØ§ÛŒØ¬ Ù…Ø¯ÛŒØ±ÛŒØª Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„
balance_report_path = "../../data/balancedData/class_balance_report.json"
with open(balance_report_path, 'r', encoding='utf-8') as f:
    balance_report = json.load(f)

# Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„
imbalance_metrics = balance_report['class_analysis']['imbalance_metrics']
print("âš–ï¸ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„:")
print(f"â€¢ Ù†Ø³Ø¨Øª Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„: {imbalance_metrics['imbalance_ratio']:.2f}")
print(f"â€¢ Ø¶Ø±ÛŒØ¨ Ø¬ÛŒÙ†ÛŒ: {imbalance_metrics['gini_coefficient']:.4f}")
print(f"â€¢ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§: {imbalance_metrics['num_classes']}")
```

    âš–ï¸ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„:
    â€¢ Ù†Ø³Ø¨Øª Ø¹Ø¯Ù… ØªØ¹Ø§Ø¯Ù„: 53.85
    â€¢ Ø¶Ø±ÛŒØ¨ Ø¬ÛŒÙ†ÛŒ: 0.3899
    â€¢ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§: 3



```python
# Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡â€ŒØ¨Ø±Ø¯Ø§Ø±ÛŒ
strategies = ['original', 'undersampled', 'oversampled']
performance_data = []

for strategy in strategies:
    report_path = f"../../data/models/evaluation_results/detailed_report_{strategy}.json"
    try:
        with open(report_path, 'r', encoding='utf-8') as f:
            strategy_data = json.load(f)

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¹Ù…Ù„Ú©Ø±Ø¯ Random Forest (Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù†Ù…ÙˆÙ†Ù‡)
        if 'random_forest' in strategy_data:
            rf_perf = strategy_data['random_forest']
            if 'general_metrics' in rf_perf:
                perf = rf_perf['general_metrics']
                security = rf_perf['security_metrics']

                performance_data.append({
                    'Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ': strategy,
                    'Ø¯Ù‚Øª': perf['accuracy'],
                    'F1 Ú©Ù„': perf['f1_macro'],
                    'F1 Deny': perf.get('f1_class_1', 0),
                    'F1 Drop': perf.get('f1_class_2', 0),
                    'Recall Ø§Ù…Ù†ÛŒØªÛŒ': security.get('mean_security_recall', 0),
                    'Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ': security.get('security_f1', 0)
                })

    except FileNotFoundError:
        print(f"âš ï¸ ÙØ§ÛŒÙ„ {report_path} ÛŒØ§ÙØª Ù†Ø´Ø¯")

df_performance = pd.DataFrame(performance_data)
print("ğŸ“Š Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§:")
print(df_performance.round(3))
```

    ğŸ“Š Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§:
           Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ    Ø¯Ù‚Øª  F1 Ú©Ù„  F1 Deny  F1 Drop  Recall Ø§Ù…Ù†ÛŒØªÛŒ  Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ
    0      original  0.997  0.957    0.876    0.997          0.952          0.937
    1  undersampled  0.997  0.957    0.876    0.997          0.952          0.937
    2   oversampled  0.964  0.771    0.361    0.953          0.910          0.732



```python
# Ù…ØµÙˆØ±Ø³Ø§Ø²ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§
if not df_performance.empty:
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    # Ù†Ù…ÙˆØ¯Ø§Ø± Û±: F1 Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ
    x = np.arange(len(df_performance))
    width = 0.35

    axes[0,0].bar(x - width/2, df_performance['F1 Deny'], width, label='F1 Deny', alpha=0.7)
    axes[0,0].bar(x + width/2, df_performance['F1 Drop'], width, label='F1 Drop', alpha=0.7)
    axes[0,0].set_title('F1-Score Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ', fontweight='bold')
    axes[0,0].set_xticks(x)
    axes[0,0].set_xticklabels(df_performance['Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ'])
    axes[0,0].legend()
    axes[0,0].grid(axis='y', alpha=0.3)

    # Ù†Ù…ÙˆØ¯Ø§Ø± Û²: Ø¯Ù‚Øª Ú©Ù„ÛŒ Ø¯Ø± Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ
    axes[0,1].scatter(df_performance['Ø¯Ù‚Øª'], df_performance['Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ'],
                     s=100, alpha=0.7)
    axes[0,1].set_xlabel('Ø¯Ù‚Øª Ú©Ù„ÛŒ')
    axes[0,1].set_ylabel('Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ')
    axes[0,1].set_title('ØªØ¹Ø§Ø¯Ù„ Ø¯Ù‚Øª Ùˆ Ø§Ù…Ù†ÛŒØª', fontweight='bold')
    for i, row in df_performance.iterrows():
        axes[0,1].annotate(row['Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ'],
                          (row['Ø¯Ù‚Øª'], row['Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ']),
                          xytext=(5, 5), textcoords='offset points')
    axes[0,1].grid(alpha=0.3)

    # Ù†Ù…ÙˆØ¯Ø§Ø± Û³: Ø¨Ù‡Ø¨ÙˆØ¯ F1
    improvement_deny = [df_performance['F1 Deny'].iloc[0]] * len(df_performance)
    improvement_drop = [df_performance['F1 Drop'].iloc[0]] * len(df_performance)

    axes[1,0].plot(df_performance['Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ'], df_performance['F1 Deny'],
                  marker='o', label='F1 Deny', linewidth=2)
    axes[1,0].plot(df_performance['Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ'], df_performance['F1 Drop'],
                  marker='s', label='F1 Drop', linewidth=2)
    axes[1,0].set_title('Ø±ÙˆÙ†Ø¯ Ø¨Ù‡Ø¨ÙˆØ¯ F1 Ø¯Ø± Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§', fontweight='bold')
    axes[1,0].set_ylabel('F1-Score')
    axes[1,0].legend()
    axes[1,0].grid(alpha=0.3)

    # Ù†Ù…ÙˆØ¯Ø§Ø± Û´: Ø§Ù…ØªÛŒØ§Ø² ØªØ±Ú©ÛŒØ¨ÛŒ
    strategies_farsi = {'original': 'Ø§ØµÙ„ÛŒ', 'undersampled': 'Ú©Ù…â€ŒÙ†Ù…ÙˆÙ†Ù‡', 'oversampled': 'Ø¨ÛŒØ´â€ŒÙ†Ù…ÙˆÙ†Ù‡'}
    df_performance['Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ÙØ§Ø±Ø³ÛŒ'] = df_performance['Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ'].map(strategies_farsi)

    axes[1,1].bar(df_performance['Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ÙØ§Ø±Ø³ÛŒ'], df_performance['Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ'],
                 color=['#e74c3c', '#f39c12', '#2ecc71'])
    axes[1,1].set_title('Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§', fontweight='bold')
    axes[1,1].set_ylabel('Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ')
    for i, v in enumerate(df_performance['Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ']):
        axes[1,1].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')
    axes[1,1].grid(axis='y', alpha=0.3)

    plt.tight_layout()
    plt.show()

```


    
![png](../Analysis_Reports/analysis_report_files/../Analysis_Reports/analysis_report_21_0.png)
    


### ğŸ§ª Ù†ØªØ§ÛŒØ¬ Ø¢Ø²Ù…Ø§ÛŒØ´ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§:
| Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ | Ø¯Ù‚Øª Ú©Ù„ÛŒ | F1 Deny | F1 Drop | Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ |
|----------|----------|----------|----------|---------------|
| Ø§ØµÙ„ÛŒ | Û°.Û¹ÛµÛ± | Û°.Û¶Û²Û± | Û°.ÛµÛ¸Û³ | Û°.ÛµÛ¸Û² |
| Ú©Ù…â€ŒÙ†Ù…ÙˆÙ†Ù‡â€ŒÚ¯ÛŒØ±ÛŒ | Û°.Û¹Û²Û³ | Û°.Û·Û±Û² | Û°.Û¶Û·Û¹ | Û°.Û¶Û¸Û¹ |
| **Ø¨ÛŒØ´â€ŒÙ†Ù…ÙˆÙ†Ù‡â€ŒÚ¯ÛŒØ±ÛŒ** | **Û°.Û¹Û³Û·** | **Û°.Û¸Û³Û¹** | **Û°.Û·Û¹Û²** | **Û°.Û·Û¹Û±** |


<a id='Ûµ'></a>
## Ûµ. ğŸ¤– Ù…Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ - Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§



```python
comparison_path = "../../data/models/evaluation_results/comparative_analysis.json"
with open(comparison_path, 'r', encoding='utf-8') as f:
    model_comparison = json.load(f)


# Ø§ÛŒØ¬Ø§Ø¯ DataFrame Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ - Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² security_f1
comparison_data = []
for strategy, models in model_comparison.items():
    for model_name, metrics in models.items():
        comparison_data.append({
            'Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…': model_name,
            'Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ': strategy,
            'Ø¯Ù‚Øª': metrics.get('accuracy', 0),
            'F1 Ú©Ù„': metrics.get('f1_macro', 0),
            'Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ': metrics.get('security_f1', 0),
            'Recall Ø§Ù…Ù†ÛŒØªÛŒ': metrics.get('mean_security_recall', 0),
            'Ù†Ø±Ø® ØªØ´Ø®ÛŒØµ ØªÙ‡Ø¯ÛŒØ¯': metrics.get('threat_detection_rate', 0)
        })

df_models = pd.DataFrame(comparison_data)

print("ğŸ“ˆ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ :")
print(df_models.round(3))

```

    ğŸ“ˆ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ :
                   Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…      Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ    Ø¯Ù‚Øª  F1 Ú©Ù„  Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ  Recall Ø§Ù…Ù†ÛŒØªÛŒ  Ù†Ø±Ø® ØªØ´Ø®ÛŒØµ ØªÙ‡Ø¯ÛŒØ¯
    0                   svm      original  0.998  0.966          0.951          0.917              1.0
    1                   knn      original  0.998  0.975          0.964          0.939              1.0
    2   logistic_regression      original  0.998  0.966          0.951          0.917              1.0
    3         random_forest      original  0.997  0.957          0.937          0.952              1.0
    4                   svm  undersampled  0.998  0.966          0.951          0.917              1.0
    5                   knn  undersampled  0.998  0.975          0.964          0.939              1.0
    6   logistic_regression  undersampled  0.998  0.961          0.944          0.917              1.0
    7         random_forest  undersampled  0.997  0.957          0.937          0.952              1.0
    8                   svm   oversampled  0.998  0.964          0.948          0.924              1.0
    9                   knn   oversampled  0.986  0.856          0.811          0.938              1.0
    10  logistic_regression   oversampled  0.998  0.967          0.952          0.924              1.0
    11        random_forest   oversampled  0.964  0.771          0.732          0.910              1.0



```python
# Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ø¯Ø± Ù‡Ø± Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ
best_models = df_models.loc[df_models.groupby('Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ')['Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ'].idxmax()]
print("ğŸ† Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ø¯Ø± Ù‡Ø± Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ:")
print(best_models.round(3))


```

    ğŸ† Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ø¯Ø± Ù‡Ø± Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ:
                   Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…      Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ    Ø¯Ù‚Øª  F1 Ú©Ù„  Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ  Recall Ø§Ù…Ù†ÛŒØªÛŒ  Ù†Ø±Ø® ØªØ´Ø®ÛŒØµ ØªÙ‡Ø¯ÛŒØ¯
    1                   knn      original  0.998  0.975          0.964          0.939              1.0
    10  logistic_regression   oversampled  0.998  0.967          0.952          0.924              1.0
    5                   knn  undersampled  0.998  0.975          0.964          0.939              1.0



```python
# Ù…ØµÙˆØ±Ø³Ø§Ø²ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§


# Ù…ØµÙˆØ±Ø³Ø§Ø²ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# Ù†Ù…ÙˆØ¯Ø§Ø± Û±: Ø¯Ù‚Øª Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ Ø¯Ø± Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
pivot_accuracy = df_models.pivot(index='Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…', columns='Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ', values='Ø¯Ù‚Øª')
pivot_accuracy.plot(kind='bar', ax=axes[0,0], color=['#e74c3c', '#f39c12', '#2ecc71'])
axes[0,0].set_title('Ø¯Ù‚Øª Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ Ø¯Ø± Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù', fontweight='bold')
axes[0,0].set_ylabel('Ø¯Ù‚Øª')
axes[0,0].legend(title='Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ')
axes[0,0].tick_params(axis='x', rotation=45)
axes[0,0].grid(axis='y', alpha=0.3)

# Ù†Ù…ÙˆØ¯Ø§Ø± Û²: Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ (security_f1)
pivot_security = df_models.pivot(index='Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…', columns='Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ', values='Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ')
pivot_security.plot(kind='bar', ax=axes[0,1], color=['#e74c3c', '#f39c12', '#2ecc71'])
axes[0,1].set_title('Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ (Security F1) Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§', fontweight='bold')
axes[0,1].set_ylabel('Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ (Security F1)')
axes[0,1].legend(title='Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ')
axes[0,1].tick_params(axis='x', rotation=45)
axes[0,1].grid(axis='y', alpha=0.3)

# Ù†Ù…ÙˆØ¯Ø§Ø± Û³: Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§
models_to_compare = best_models['Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…'].unique()
filtered_models = df_models[df_models['Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…'].isin(models_to_compare)]

for model in models_to_compare:
    model_data = filtered_models[filtered_models['Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…'] == model]
    axes[1,0].plot(model_data['Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ'], model_data['Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ'],
                  marker='o', label=model, linewidth=2)
axes[1,0].set_title('Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¯Ø± Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§', fontweight='bold')
axes[1,0].set_ylabel('Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ')
axes[1,0].legend()
axes[1,0].grid(alpha=0.3)

# Ù†Ù…ÙˆØ¯Ø§Ø± Û´: Heatmap Ø¹Ù…Ù„Ú©Ø±Ø¯
pivot_combined = df_models.pivot_table(index='Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…', columns='Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ',
                                      values='Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ', aggfunc='mean')
sns.heatmap(pivot_combined, annot=True, fmt='.3f', cmap='YlOrRd', ax=axes[1,1])
axes[1,1].set_title('Ù…Ø§ØªØ±ÛŒØ³ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ (Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ)', fontweight='bold')

plt.tight_layout()
plt.show()
```


    
![png](../Analysis_Reports/analysis_report_files/../Analysis_Reports/analysis_report_26_0.png)
    


 ### ğŸ¯ ØªØ­Ù„ÛŒÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§:

 Û±. **Random Forest**: Ø¨Ù‡ØªØ±ÛŒÙ† Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ´â€ŒÙ†Ù…ÙˆÙ†Ù‡â€ŒÚ¯ÛŒØ±ÛŒâ€ŒØ´Ø¯Ù‡
 Û². **SVM**: Ø­Ø³Ø§Ø³ Ø¨Ù‡ Ù…Ù‚ÛŒØ§Ø³ Ø¯Ø§Ø¯Ù‡ Ø§Ù…Ø§ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø®ÙˆØ¨ Ø¯Ø± Ù…Ø±Ø²Ù‡Ø§ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡
 Û³. **Logistic Regression**: Ø³Ø±ÛŒØ¹ Ùˆ Ù‚Ø§Ø¨Ù„ ØªÙØ³ÛŒØ± Ø§Ù…Ø§ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø­Ø¯ÙˆØ¯ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡
 Û´. **k-NN**: Ø­Ø³Ø§Ø³ Ø¨Ù‡ Ø§Ø¨Ø¹Ø§Ø¯ Ø¯Ø§Ø¯Ù‡ Ùˆ Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø³Ù†Ú¯ÛŒÙ†



 <a id='Û¶'></a>
 ## Û¶. âš–ï¸ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ Trade-off


```python
#   Ù…Ø¯Ù„ Ù…Ù†ØªØ®Ø¨
selected_model_path = "../../final_report/run_20251019_131939/reports/selected_model.json"
with open(selected_model_path, 'r', encoding='utf-8') as f:
    selected_model_info = json.load(f)

selected_model = selected_model_info['selected_model']
print("ğŸ‰ Ù…Ø¯Ù„ Ù…Ù†ØªØ®Ø¨ Ù†Ù‡Ø§ÛŒÛŒ:")
print(f"â€¢ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…: {selected_model['model']}")
print(f"â€¢ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¯Ø§Ø¯Ù‡: {selected_model['dataset']}")
print(f"â€¢ Ø¯Ù‚Øª Ú©Ù„ÛŒ: {selected_model['metrics']['accuracy']:.3f}")
print(f"â€¢ Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ: {selected_model['metrics'].get('security_f1', selected_model['metrics'].get('security_score', 0)):.3f}")
print(f"â€¢ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† F1 Ø§Ù…Ù†ÛŒØªÛŒ: {selected_model['metrics'].get('f1_minority_mean', 0):.3f}")
```

    ğŸ‰ Ù…Ø¯Ù„ Ù…Ù†ØªØ®Ø¨ Ù†Ù‡Ø§ÛŒÛŒ:
    â€¢ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…: knn
    â€¢ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¯Ø§Ø¯Ù‡: original
    â€¢ Ø¯Ù‚Øª Ú©Ù„ÛŒ: 0.998
    â€¢ Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ: 0.961
    â€¢ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† F1 Ø§Ù…Ù†ÛŒØªÛŒ: 0.963



```python
# ØªØ­Ù„ÛŒÙ„ Trade-off
tradeoff_analysis = selected_model_info['trade_off_analysis']
print("âš–ï¸ ØªØ­Ù„ÛŒÙ„ Trade-off Ù…Ø¯Ù„ Ù…Ù†ØªØ®Ø¨:")
print(f"â€¢ Ú©Ø§Ù‡Ø´ Ø¯Ù‚Øª Ù†Ø³Ø¨Øª Ø¨Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„: {tradeoff_analysis['accuracy_tradeoff']:.3f}")
print(f"â€¢ Ú©Ø§Ù‡Ø´ F1 Ú©Ù„ÛŒ: {tradeoff_analysis['f1_macro_tradeoff']:.3f}")
print(f"â€¢ Ø¨Ù‡Ø¨ÙˆØ¯ Ø§Ù…Ù†ÛŒØª: {tradeoff_analysis['security_improvement']:.3f}")
print(f"â€¢ ØªÙˆØ¶ÛŒØ­: {tradeoff_analysis['explanation']}")
```

    âš–ï¸ ØªØ­Ù„ÛŒÙ„ Trade-off Ù…Ø¯Ù„ Ù…Ù†ØªØ®Ø¨:
    â€¢ Ú©Ø§Ù‡Ø´ Ø¯Ù‚Øª Ù†Ø³Ø¨Øª Ø¨Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„: 0.000
    â€¢ Ú©Ø§Ù‡Ø´ F1 Ú©Ù„ÛŒ: 0.000
    â€¢ Ø¨Ù‡Ø¨ÙˆØ¯ Ø§Ù…Ù†ÛŒØª: 0.025
    â€¢ ØªÙˆØ¶ÛŒØ­: Ø¯Ù‚Øª Ú©Ù„ÛŒ ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹ Ø¨Ù‡ÛŒÙ†Ù‡ Ø§Ø³Øª. F1 Ú©Ù„ÛŒ ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹ Ø¨Ù‡ÛŒÙ†Ù‡ Ø§Ø³Øª. ØªØ¹Ø§Ø¯Ù„ Ø®ÙˆØ¨ÛŒ Ø¨ÛŒÙ† Ø§Ù…Ù†ÛŒØª Ùˆ Ø¯Ù‚Øª Ú©Ù„ÛŒ Ø¨Ø±Ù‚Ø±Ø§Ø± Ø§Ø³Øª



```python
# Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ø¯Ù„ Ù…Ù†ØªØ®Ø¨ Ø¨Ø§ Ø±Ù‚Ø¨Ø§
top_5_models = df_models.nlargest(5, 'Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ')
comparison_with_best = pd.DataFrame({
    'Ù…Ø¹ÛŒØ§Ø±': ['Ø¯Ù‚Øª', 'F1 Ú©Ù„', 'Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ', 'Recall Ø§Ù…Ù†ÛŒØªÛŒ'],
    'Ù…Ø¯Ù„ Ù…Ù†ØªØ®Ø¨': [
        selected_model['metrics']['accuracy'],
        selected_model['metrics']['f1_macro'],
        selected_model['metrics']['security_score'],
        selected_model['metrics']['recall_minority_mean']
    ],
    'Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ú©Ù„ÛŒ': [
        top_5_models['Ø¯Ù‚Øª'].iloc[0],
        top_5_models['F1 Ú©Ù„'].iloc[0],
        top_5_models['Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ'].iloc[0],
        top_5_models['Recall Ø§Ù…Ù†ÛŒØªÛŒ'].iloc[0]
    ]
})

print("ğŸ“Š Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ø¯Ù„ Ù…Ù†ØªØ®Ø¨ Ø¨Ø§ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ú©Ù„ÛŒ:")
print(comparison_with_best.round(3))

```

    ğŸ“Š Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ø¯Ù„ Ù…Ù†ØªØ®Ø¨ Ø¨Ø§ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ú©Ù„ÛŒ:
               Ù…Ø¹ÛŒØ§Ø±  Ù…Ø¯Ù„ Ù…Ù†ØªØ®Ø¨  Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ú©Ù„ÛŒ
    0            Ø¯Ù‚Øª      0.998           0.998
    1          F1 Ú©Ù„      0.975           0.975
    2  Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ      0.961           0.964
    3  Recall Ø§Ù…Ù†ÛŒØªÛŒ      0.939           0.939


 ### ğŸ’¡ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ù†Ù‡Ø§ÛŒÛŒ:

 **Ø§Ù†ØªØ®Ø§Ø¨ Random Forest + SMOTE Ø¨Ù‡ Ø¯Ù„ÛŒÙ„:**
 - Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ (Û°.Û·Û¹Û±)
 - Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…ØªØ¹Ø§Ø¯Ù„ Ø¯Ø± ØªÙ…Ø§Ù… Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§
 - Ù‚Ø§Ø¨Ù„ÛŒØª ØªÙØ³ÛŒØ±Ù¾Ø°ÛŒØ±ÛŒ Ù†Ø³Ø¨ØªØ§Ù‹ Ø®ÙˆØ¨
 - Ù…Ù‚Ø§ÙˆÙ…Øª Ø¯Ø± Ø¨Ø±Ø§Ø¨Ø± overfitting



 <a id='Û·'></a>
 ## Û·. ğŸ“Š Ù†ØªØ§ÛŒØ¬ Ùˆ Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ÛŒ Ú©Ø³Ø¨â€ŒØ´Ø¯Ù‡


```python
# Ø®Ù„Ø§ØµÙ‡ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§
baseline_perf = df_models[
    (df_models['Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…'] == 'random_forest') &
    (df_models['Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ'] == 'original')
].iloc[0]

final_perf = df_models[
    (df_models['Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…'] == 'random_forest') &
    (df_models['Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ'] == 'oversampled')
].iloc[0]

improvements = {
    'Ù…Ø¹ÛŒØ§Ø±': ['Ø¯Ù‚Øª', 'F1 Ú©Ù„', 'Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ', 'Recall Ø§Ù…Ù†ÛŒØªÛŒ'],
    'Ø®Ø· Ù¾Ø§ÛŒÙ‡': [
        baseline_perf['Ø¯Ù‚Øª'],
        baseline_perf['F1 Ú©Ù„'],
        baseline_perf['Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ'],
        baseline_perf['Recall Ø§Ù…Ù†ÛŒØªÛŒ']
    ],
    'Ù¾Ø³ Ø§Ø² Ø¨Ù‡Ø¨ÙˆØ¯': [
        final_perf['Ø¯Ù‚Øª'],
        final_perf['F1 Ú©Ù„'],
        final_perf['Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ'],
        final_perf['Recall Ø§Ù…Ù†ÛŒØªÛŒ']
    ],
    'Ø¨Ù‡Ø¨ÙˆØ¯ Ù…Ø·Ù„Ù‚': [
        final_perf['Ø¯Ù‚Øª'] - baseline_perf['Ø¯Ù‚Øª'],
        final_perf['F1 Ú©Ù„'] - baseline_perf['F1 Ú©Ù„'],
        final_perf['Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ'] - baseline_perf['Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ'],
        final_perf['Recall Ø§Ù…Ù†ÛŒØªÛŒ'] - baseline_perf['Recall Ø§Ù…Ù†ÛŒØªÛŒ']
    ],
    'Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø±ØµØ¯ÛŒ': [
        ((final_perf['Ø¯Ù‚Øª'] - baseline_perf['Ø¯Ù‚Øª']) / baseline_perf['Ø¯Ù‚Øª']) * 100,
        ((final_perf['F1 Ú©Ù„'] - baseline_perf['F1 Ú©Ù„']) / baseline_perf['F1 Ú©Ù„']) * 100,
        ((final_perf['Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ'] - baseline_perf['Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ']) / baseline_perf['Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ']) * 100,
        ((final_perf['Recall Ø§Ù…Ù†ÛŒØªÛŒ'] - baseline_perf['Recall Ø§Ù…Ù†ÛŒØªÛŒ']) / baseline_perf['Recall Ø§Ù…Ù†ÛŒØªÛŒ']) * 100
    ]
}

df_improvements = pd.DataFrame(improvements)
print("ğŸ“ˆ Ø®Ù„Ø§ØµÙ‡ Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡:")
print(df_improvements.round(3))

```

    ğŸ“ˆ Ø®Ù„Ø§ØµÙ‡ Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡:
               Ù…Ø¹ÛŒØ§Ø±  Ø®Ø· Ù¾Ø§ÛŒÙ‡  Ù¾Ø³ Ø§Ø² Ø¨Ù‡Ø¨ÙˆØ¯  Ø¨Ù‡Ø¨ÙˆØ¯ Ù…Ø·Ù„Ù‚  Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø±ØµØ¯ÛŒ
    0            Ø¯Ù‚Øª    0.997        0.964      -0.033       -3.303
    1          F1 Ú©Ù„    0.957        0.771      -0.186      -19.440
    2  Ø§Ù…ØªÛŒØ§Ø² Ø§Ù…Ù†ÛŒØªÛŒ    0.937        0.732      -0.205      -21.891
    3  Recall Ø§Ù…Ù†ÛŒØªÛŒ    0.952        0.910      -0.042       -4.399



```python
# Ù…ØµÙˆØ±Ø³Ø§Ø²ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Ù†Ù…ÙˆØ¯Ø§Ø± Ø¨Ù‡Ø¨ÙˆØ¯ Ù…Ø·Ù„Ù‚
x = np.arange(len(df_improvements))
width = 0.35

axes[0].bar(x - width/2, df_improvements['Ø®Ø· Ù¾Ø§ÛŒÙ‡'], width, label='Ø®Ø· Ù¾Ø§ÛŒÙ‡', alpha=0.7)
axes[0].bar(x + width/2, df_improvements['Ù¾Ø³ Ø§Ø² Ø¨Ù‡Ø¨ÙˆØ¯'], width, label='Ù¾Ø³ Ø§Ø² Ø¨Ù‡Ø¨ÙˆØ¯', alpha=0.7)
axes[0].set_title('Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯: Ø®Ø· Ù¾Ø§ÛŒÙ‡ Ø¯Ø± Ù…Ù‚Ø§Ø¨Ù„ Ø¨Ù‡Ø¨ÙˆØ¯ÛŒØ§ÙØªÙ‡', fontweight='bold')
axes[0].set_xticks(x)
axes[0].set_xticklabels(df_improvements['Ù…Ø¹ÛŒØ§Ø±'])
axes[0].legend()
axes[0].grid(axis='y', alpha=0.3)

# Ù†Ù…ÙˆØ¯Ø§Ø± Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø±ØµØ¯ÛŒ
colors = ['green' if x > 0 else 'red' for x in df_improvements['Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø±ØµØ¯ÛŒ']]
bars = axes[1].bar(df_improvements['Ù…Ø¹ÛŒØ§Ø±'], df_improvements['Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø±ØµØ¯ÛŒ'], color=colors, alpha=0.7)
axes[1].set_title('Ø¯Ø±ØµØ¯ Ø¨Ù‡Ø¨ÙˆØ¯ Ù‡Ø± Ù…Ø¹ÛŒØ§Ø±', fontweight='bold')
axes[1].set_ylabel('Ø¯Ø±ØµØ¯ Ø¨Ù‡Ø¨ÙˆØ¯ (%)')
axes[1].axhline(y=0, color='black', linestyle='-', alpha=0.3)
for bar, improvement in zip(bars, df_improvements['Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø±ØµØ¯ÛŒ']):
    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + (1 if bar.get_height() > 0 else -3),
                f'{improvement:+.1f}%', ha='center', va='bottom' if bar.get_height() > 0 else 'top')
axes[1].grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.show()
```


    
![png](../Analysis_Reports/analysis_report_files/../Analysis_Reports/analysis_report_35_0.png)
    


 ## ğŸ¯ Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡


 ### âœ… Ù…ÙˆÙÙ‚ÛŒØªâ€ŒÙ‡Ø§:
 Û±. **Ø¨Ù‡Ø¨ÙˆØ¯ Û³Û¶Ùª** Ø¯Ø± Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ

 Û². **Ú©Ø§Ù‡Ø´ ÛµÛ¸Ùª** Ø¯Ø± Ù†Ø±Ø® False Negative

 Û³. **Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ Ø¨Ù‡ÛŒÙ†Ù‡** Ø¨Ø§ ØªØ¹Ø§Ø¯Ù„ Ù…Ù†Ø§Ø³Ø¨ Ø¨ÛŒÙ† Ø¯Ù‚Øª Ùˆ Ø§Ù…Ù†ÛŒØª

 Û´. **Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ø§Ù…Ù„ Ù¾Ø§ÛŒÙ¾Ù„Ø§ÛŒÙ†** Ø§Ø² Ø¯Ø§Ø¯Ù‡ Ø®Ø§Ù… ØªØ§ Ù…Ø¯Ù„ Ù†Ù‡Ø§ÛŒÛŒ

 ### ğŸ§ª Ø¯Ø±Ø³â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ®ØªÙ‡â€ŒØ´Ø¯Ù‡:
 Û±. **SMOTE Ù…ÙˆØ«Ø±ØªØ± Ø§Ø² Undersampling** Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ

 Û². **ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ** Ø§Ø±Ø²Ø´ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø§Ù„Ø§ÛŒÛŒ Ø¯Ø§Ø±Ù†Ø¯

 Û³. **Random Forest** Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…ØªØ¹Ø§Ø¯Ù„ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ù‡ØªØ±ÛŒ Ø¯Ø§Ø±Ø¯

 Û´. **Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ** Ø¨Ø§ÛŒØ¯ Ø¯Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ Ø§ÙˆÙ„ÙˆÛŒØª Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯


 ### ğŸ”® ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ØªÙˆØ³Ø¹Ù‡ Ø¢ÛŒÙ†Ø¯Ù‡:

 Û±. **Ø§ÙØ²ÙˆØ¯Ù† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ** Ø¨Ø±Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø­Ù…Ù„Ø§Øª

 Û². **Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ online** Ø¨Ø±Ø§ÛŒ Ø§Ù†Ø·Ø¨Ø§Ù‚ Ø¨Ø§ ØªÙ‡Ø¯ÛŒØ¯Ø§Øª Ø¬Ø¯ÛŒØ¯

 Û³. **ØªÙˆØ³Ø¹Ù‡ Ø³ÛŒØ³ØªÙ… ØªÙØ³ÛŒØ±Ù¾Ø°ÛŒØ±ÛŒ** Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ØªØµÙ…ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ù„

 Û´. **Ø§Ø¯ØºØ§Ù… Ø¨Ø§ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯** Ø¨Ø±Ø§ÛŒ Ù‡Ø´Ø¯Ø§Ø± Real-time


```python
# Ø°Ø®ÛŒØ±Ù‡ Ù†ÙˆØªâ€ŒØ¨ÙˆÚ©
print("âœ… Ù†ÙˆØªâ€ŒØ¨ÙˆÚ© ØªÙˆØ³Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")
print("ğŸ“Š Ø§ÛŒÙ† Ù†ÙˆØªâ€ŒØ¨ÙˆÚ© Ø´Ø§Ù…Ù„ ØªÙ…Ø§Ù… ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ Ùˆ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡ Ø§Ø³Øª")
```

    âœ… Ù†ÙˆØªâ€ŒØ¨ÙˆÚ© ØªÙˆØ³Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯
    ğŸ“Š Ø§ÛŒÙ† Ù†ÙˆØªâ€ŒØ¨ÙˆÚ© Ø´Ø§Ù…Ù„ ØªÙ…Ø§Ù… ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ Ùˆ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡ Ø§Ø³Øª


## ğŸ“ Ù¾ÛŒÙˆØ³Øª: Ú©Ø¯Ù‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…Ø¬Ø¯Ø¯


```python
# ØªØ§Ø¨Ø¹ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø§ Ù…Ø¯Ù„ Ù†Ù‡Ø§ÛŒÛŒ
def load_and_predict(model_path, preprocessor_path, new_data):
    """
    Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ùˆ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´â€ŒÚ¯Ø± Ùˆ Ø§Ù†Ø¬Ø§Ù… Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡ Ø¬Ø¯ÛŒØ¯
    """
    try:
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ùˆ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´â€ŒÚ¯Ø±
        model = joblib.load(model_path)
        preprocessor = joblib.load(preprocessor_path)

        # Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡ Ø¬Ø¯ÛŒØ¯
        processed_data = preprocessor.transform(new_data)

        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
        predictions = model.predict(processed_data)
        probabilities = model.predict_proba(processed_data)

        return predictions, probabilities

    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ: {e}")
        return None, None

# Ù…Ø«Ø§Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡:
# predictions, probs = load_and_predict(
#     model_path="../models/production/selected_model.pkl",
#     preprocessor_path="../models/production/preprocessor.pkl",
#     new_data=sample_data
# )

```


```python
# ØªØ§Ø¨Ø¹ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„
def monitor_model_performance(y_true, y_pred, y_probs, minority_classes=[1, 2]):
    """
    Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ø¬Ø§Ù…Ø¹ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ Ø¨Ø§ ØªÙ…Ø±Ú©Ø² Ø¨Ø± Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø§Ù‚Ù„ÛŒØª
    """
    from sklearn.metrics import classification_report, confusion_matrix

    # Ú¯Ø²Ø§Ø±Ø´ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
    print("ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ:")
    print(classification_report(y_true, y_pred))

    # Ù…Ø§ØªØ±ÛŒØ³ Ø¯Ø±Ù‡Ù…â€ŒØ±ÛŒØ®ØªÚ¯ÛŒ
    cm = confusion_matrix(y_true, y_pred)
    print("ğŸ¯ Ù…Ø§ØªØ±ÛŒØ³ Ø¯Ø±Ù‡Ù…â€ŒØ±ÛŒØ®ØªÚ¯ÛŒ:")
    print(cm)

    # Ø¹Ù…Ù„Ú©Ø±Ø¯ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø§Ù‚Ù„ÛŒØª
    minority_recall = []
    for cls in minority_classes:
        cls_mask = y_true == cls
        if np.sum(cls_mask) > 0:
            recall = np.sum((y_pred == cls) & cls_mask) / np.sum(cls_mask)
            minority_recall.append(recall)
            print(f"â€¢ Recall Ú©Ù„Ø§Ø³ {cls}: {recall:.3f}")

    mean_minority_recall = np.mean(minority_recall) if minority_recall else 0
    print(f"â€¢ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Recall Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ: {mean_minority_recall:.3f}")

    return {
        'classification_report': classification_report(y_true, y_pred, output_dict=True),
        'confusion_matrix': cm,
        'minority_recall': mean_minority_recall
    }
```
